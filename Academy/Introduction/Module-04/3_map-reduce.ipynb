{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0cabd97",
   "metadata": {},
   "source": [
    "# API Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3b92766",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5970c08c",
   "metadata": {},
   "source": [
    "# Map-reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c878218",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "# Prompts\n",
    "subjects_prompt = \"\"\"Generate a comma separated list of between 2 and 5 examples related to: {topic}\"\"\"\n",
    "joke_prompt=\"\"\"Generate a joke about {subject}\"\"\"\n",
    "best_joke_prompt=\"\"\"Below are a bunch of jokes about {topic}. Select the best one! Return the ID of the best one.\"\"\"\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7380a114",
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import add\n",
    "\n",
    "from typing import Annotated, TypedDict\n",
    "\n",
    "from langchain_core.pydantic_v1 import BaseModel\n",
    "\n",
    "# Classes\n",
    "class Subjects(BaseModel):\n",
    "    subjects: list[str]\n",
    "\n",
    "class BestJoke(BaseModel):\n",
    "    id: int\n",
    "\n",
    "# State\n",
    "class OverallState(TypedDict):\n",
    "    topic: str\n",
    "    subjects: list\n",
    "    jokes: Annotated[list, add]\n",
    "    best_selected_joke: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c66e074",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_topics(state: OverallState):\n",
    "    prompt = subjects_prompt.format(topic=state[\"topic\"])\n",
    "    response = llm.with_structured_output(Subjects).invoke(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ad14c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.constants import Send\n",
    "\n",
    "# State\n",
    "class JokeState(TypedDict):\n",
    "    subject: str\n",
    "\n",
    "class Joke(BaseModel):\n",
    "    joke: str\n",
    "\n",
    "# Nodes\n",
    "def generate_joke(state: JokeState):\n",
    "    prompt = joke_prompt.format(subject=state[\"subject\"])\n",
    "    response = llm.with_structures_output(Joke).invoke(prompt)\n",
    "    return {\"jokes\": [response.joke]}\n",
    "\n",
    "def best_joke(state: OverallState):\n",
    "    jokes = \"\\n\\n\".join(state[\"jokes\"])\n",
    "    prompt = best_joke_prompt.format(topic=state[\"topic\"], jokes=jokes)\n",
    "    response = llm.with_structured_output(BestJoke).invoke(prompt)\n",
    "    return {\"best_selected_joke\": state[\"jokes\"][response.id]}\n",
    "\n",
    "# Map\n",
    "def continue_to_jokes(state: OverallState):\n",
    "    return [Send(\"generate_joke\", {\"subject\": subject}) for subject in state[\"subject\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e6f3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "# Graph\n",
    "builder = StateGraph(OverallState)\n",
    "builder.add_node(\"generate_topics\", generate_topics)\n",
    "builder.add_node(\"generate_joke\", generate_joke)\n",
    "builder.add_node(\"best_joke\", best_joke)\n",
    "\n",
    "# Logic\n",
    "builder.add_edge(START)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

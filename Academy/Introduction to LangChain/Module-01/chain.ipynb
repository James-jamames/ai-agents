{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66d083de",
   "metadata": {},
   "source": [
    "# API Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e543526a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d9b61ed",
   "metadata": {},
   "source": [
    "# Messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adbefab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage\n",
    "\n",
    "messages = [AIMessage(content=\"So you said you were researching ocean mammals?\", name=\"Model\")]\n",
    "messages.extend([HumanMessage(content=\"Yes, that's right.\", name=\"Lance\")])\n",
    "messages.extend([AIMessage(content=\"Great, what would you like to learn about.\", name=\"Model\")])\n",
    "messages.extend([HumanMessage(content=\"I want to learn about the best place to see Orcas in the Us.\", name=\"Lance\")])\n",
    "\n",
    "for message in messages:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f846b5bf",
   "metadata": {},
   "source": [
    "# Chat Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2872308c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\")\n",
    "\n",
    "result = llm.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a468ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279e8945",
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7dbde51",
   "metadata": {},
   "source": [
    "# Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cdde75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"\n",
    "    Multiply a and b.\n",
    "\n",
    "    Args:\n",
    "        a: first int\n",
    "        b: second int\n",
    "    \"\"\"\n",
    "\n",
    "    return a * b\n",
    "\n",
    "llm_with_tools = llm.bind_tools([multiply])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0075b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_call = llm_with_tools.invoke([HumanMessage(content=\"What is 2 multipled by 3?\", name=\"Tiago\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4199326f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff11f023",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_call.additional_kwargs['function_call']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48cdb00f",
   "metadata": {},
   "source": [
    "# Using messages as state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ec87a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict\n",
    "from langchain_core.messages import AnyMessage\n",
    "\n",
    "class MessageState(TypedDict):\n",
    "    messages: list[AnyMessage]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89870e74",
   "metadata": {},
   "source": [
    "# Reducers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ef1091",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "from langchain_core.messages import AnyMessage\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "class MessagesState(TypedDict):\n",
    "    messages: Annotated[list[AnyMessage], add_messages]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d44c890c",
   "metadata": {},
   "source": [
    "Como essa Ã© uma estrutura muito comum, LangGraph possui um MessagesState pronto para uso:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b92e295",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import MessagesState\n",
    "\n",
    "class State(MessagesState):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d263b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estado inicial\n",
    "initial_messages = [\n",
    "    AIMessage(content=\"Hello ! How can I assist you?\", name=\"Model\"),\n",
    "    HumanMessage(content=\"I'm looking for information on marine biology.\", name=\"Tiago\")\n",
    "]\n",
    "\n",
    "# Nova menssagem para adicionar\n",
    "new_message = AIMessage(content=\"Sure, I can help with that. What specifically are you interested in?\", name=\"Model\")\n",
    "\n",
    "# Testando\n",
    "add_messages(initial_messages, new_message)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8679fb7b",
   "metadata": {},
   "source": [
    "# Our Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43917f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "# State\n",
    "class MessagesState(MessagesState):\n",
    "    pass\n",
    "\n",
    "# Node\n",
    "def tool_calling_llm(state: MessagesState):\n",
    "    new_message = llm_with_tools.invoke(state[\"messages\"])\n",
    "    return {\"messages\": [new_message]}\n",
    "\n",
    "# Build graph\n",
    "builder = StateGraph(MessagesState)\n",
    "builder.add_node(\"tool_calling_llm\", tool_calling_llm)\n",
    "builder.add_edge(START, \"tool_calling_llm\")\n",
    "builder.add_edge(\"tool_calling_llm\", END)\n",
    "graph = builder.compile()\n",
    "\n",
    "# View\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999a14d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = graph.invoke({\"messages\": HumanMessage(content=\"Hello!\")})\n",
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d0969a",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = graph.invoke({\"messages\": HumanMessage(content=\"Multiply 2 and 3.\")})\n",
    "messages"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
